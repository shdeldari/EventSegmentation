{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EventSegmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shdeldari/EventSegmentation/blob/TimeSeries/EventSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbb48qLnYZ0T",
        "colab_type": "code",
        "outputId": "45aac4cb-4daa-460b-d87b-c8dba8d1bf21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import nn_ops\n",
        "from tensorflow.python.ops import init_ops\n",
        "from tensorflow.python.ops import variable_scope as vs\n",
        "from tensorflow.python.framework import constant_op\n",
        "from tensorflow.python.framework import dtypes\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "from random import shuffle, choice\n",
        "from PIL import Image\n",
        "import sys\n",
        "import json\n",
        "import collections\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFzSXPlCc76Z",
        "colab_type": "code",
        "outputId": "009d5941-9baa-4059-f626-4a8bbd903f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "Input_directory = \"\"\n",
        "vidPath = \"\"\n",
        "modelPath = \"./model\"\n",
        "activeLearningInput = 1\n",
        "\n",
        "input_width = 224\n",
        "input_height = 224\n",
        "num_channels = 3\n",
        "slim = tf.contrib.slim\n",
        "n_hidden1 = 4096\n",
        "n_hidden2 = 4096\n",
        "feature_size = 4096\n",
        "learnError = 0\n",
        "n_epochs = 1\n",
        "batch_size = 2\n",
        "min_steps = batch_size\n",
        "\n",
        "lr = 1e-8\n",
        "\n",
        "jsonData = json.load(open(Input_directory))\n",
        "\n",
        "\n",
        "if activeLearningInput == \"1\":\n",
        "\tactiveLearning = True\n",
        "else:\n",
        "\tactiveLearning = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0f92421029a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mjsonData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUTFif-de9SB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(jsonData, inPath):\n",
        "\tbatchPaths = []\n",
        "\tfor vid in jsonData.keys():\n",
        "\t\t# VIRAT format\n",
        "\t\tdirName = '_'.join(vid.split('.')[0].split('_')[2:])\n",
        "\t\t\n",
        "\t\t# Other dataset file name format\n",
        "\t\t# dirName = '_'.join(vid.split('.')[0])\n",
        "\n",
        "\t\tvidPath = join(inPath,dirName)\n",
        "\t\tbatchPaths = batchPaths + sorted([str(join(vidPath, f) + '/') for f in listdir(vidPath) if isdir(join(vidPath, f))])\n",
        "\treturn batchPaths\n",
        "\n",
        "def loadMiniBatch(vidFilePath):\n",
        "\tvidName = vidFilePath.split('/')[-3]\n",
        "\tframeList = sorted([join(vidFilePath, f) for f in listdir(vidFilePath) if isfile(join(vidFilePath, f)) and f.endswith('.png')])\n",
        "\tframeList = sorted(frameList, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
        "\tits = [iter(frameList), iter(frameList[1:])]\n",
        "\tsegments = zip(*its)\n",
        "\tminibatch = []\n",
        "\tfor segment in segments:\n",
        "\t\tim = []\n",
        "\t\tnumFrames = 0\n",
        "\t\tfor j, imFile in enumerate(segment):\n",
        "\t\t\timg = Image.open(imFile)\n",
        "\t\t\timg = img.resize((input_width, input_height), Image.ANTIALIAS)\n",
        "\t\t\tim.append(np.array(img))\n",
        "\t\t\tnumFrames += 1\n",
        "\t\tminibatch.append(np.stack(im))\n",
        "\treturn vidFilePath, minibatch\n",
        "\n",
        "def broadcast(tensor, shape):\n",
        "    return tensor + tf.zeros(shape, dtype=tensor.dtype)\n",
        "\n",
        "def RNNCell(W, B, inputs, state):\n",
        "\t\"\"\"Most basic RNN: output = new_state = act(W * input + U * state + B).\"\"\"\n",
        "\tone = constant_op.constant(1, dtype=dtypes.int32)\n",
        "\tadd = math_ops.add\n",
        "\tmultiply = math_ops.multiply\n",
        "\tsigmoid = math_ops.sigmoid\n",
        "\tactivation = math_ops.tanh\n",
        "\n",
        "\tgate_inputs = math_ops.matmul(array_ops.concat([inputs, state], 1), W)\n",
        "\tgate_inputs = nn_ops.bias_add(gate_inputs, B)\n",
        "\toutput = sigmoid(gate_inputs)\n",
        "\treturn output, output\n",
        "\n",
        "def lstm_cell(W, b, forget_bias, inputs, state):\n",
        "\tone = constant_op.constant(1, dtype=dtypes.int32)\n",
        "\tadd = math_ops.add\n",
        "\tmultiply = math_ops.multiply\n",
        "\tsigmoid = math_ops.sigmoid\n",
        "\tactivation = math_ops.sigmoid\n",
        "\t# activation = math_ops.tanh\n",
        "\n",
        "\tc, h = array_ops.split(value=state, num_or_size_splits=2, axis=one)\n",
        "\n",
        "\tgate_inputs = math_ops.matmul(array_ops.concat([inputs, h], 1), W)\n",
        "\tgate_inputs = nn_ops.bias_add(gate_inputs, b)\n",
        "\t# i = input_gate, j = new_input, f = forget_gate, o = output_gate\n",
        "\ti, j, f, o = array_ops.split(value=gate_inputs, num_or_size_splits=4, axis=one)\n",
        "\n",
        "\tforget_bias_tensor = constant_op.constant(forget_bias, dtype=f.dtype)\n",
        "\n",
        "\tnew_c = add(multiply(c, sigmoid(add(f, forget_bias_tensor))), multiply(sigmoid(i), activation(j)))\n",
        "\tnew_h = multiply(activation(new_c), sigmoid(o))\n",
        "\tnew_state = array_ops.concat([new_c, new_h], 1)\n",
        "\n",
        "\treturn new_h, new_state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlwcpVOSRjpI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kZv0wHOR2vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = loadData(jsonData, vidPath)\n",
        "\n",
        "\n",
        "inputs = tf.placeholder(tf.float32, (None, w,f), name='inputs')\n",
        "learning_rate = tf.placeholder(tf.float32, [])\n",
        "is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "# Setup RNN\n",
        "init_state1 = tf.placeholder(tf.float32, [1, n_hidden1])\n",
        "W_RNN1 = vs.get_variable(\"W1\", shape=[feature_size+n_hidden1, n_hidden1])\n",
        "b_RNN1 = vs.get_variable(\"b1\", shape=[n_hidden1], initializer=init_ops.zeros_initializer(dtype=tf.float32))\n",
        "curr_state1 = init_state1\n",
        "\n",
        "# Setup LSTM\n",
        "#init_state1 = tf.placeholder(tf.float32, [1, 2*n_hidden1])\n",
        "#W_lstm1 = vs.get_variable(\"W1\", shape=[feature_size + n_hidden1, 4*n_hidden1])\n",
        "#b_lstm1 = vs.get_variable(\"b1\", shape=[4*n_hidden1], initializer=init_ops.zeros_initializer(dtype=tf.float32))\n",
        "#curr_state1 = broadcast(init_state1, [tf.shape(xs)[0], 2*n_hidden1])\n",
        "\n",
        "\n",
        "W_fc1 = tf.Variable(tf.truncated_normal([n_hidden1, feature_size], stddev=0.1))\n",
        "b_fc1 = tf.Variable(tf.constant(0.1, shape=[feature_size]))\n",
        "\n",
        "scope = 'vgg_16'\n",
        "fc_conv_padding = 'VALID'\n",
        "dropout_keep_prob=0.8\n",
        "\n",
        "r, g, b = tf.split(axis=3, num_or_size_splits=3, value=inputs * 255.0)\n",
        "VGG_MEAN = [103.939, 116.779, 123.68]\n",
        "VGG_inputs = tf.concat(values=[b - VGG_MEAN[0], g - VGG_MEAN[1], r - VGG_MEAN[2]], axis=3)\n",
        "\n",
        "with tf.variable_scope(scope, 'vgg_16', [VGG_inputs]) as sc:\n",
        "\tend_points_collection = sc.original_name_scope + '_end_points'\n",
        "\t# Collect outputs for conv2d, fully_connected and max_pool2d.\n",
        "\twith slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
        "\t\t\t\t\t\t\t\t\t\t\toutputs_collections=end_points_collection):\n",
        "\t\tnet = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
        "\t\tnet = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "\t\tnet = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
        "\t\tnet = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "\t\tnet = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
        "\t\tnet = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
        "\t\tnet = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
        "\t\tnet = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
        "\t\tnet = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
        "\t\tnet = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
        "\n",
        "\t\t# Use conv2d instead of fully_connected layers.\n",
        "\t\tnet = slim.conv2d(net, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')\n",
        "\t\tnet = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
        "\t\t\t\t\t\t\t\t\t\t\t scope='dropout6')\n",
        "\t\tnet = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
        "\t\tvgg16_Features = tf.reshape(net, (-1,4096))\n",
        "\t\t# Convert end_points_collection into a end_point dict.\n",
        "\t\tend_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
        "\n",
        "RNN_inputs = tf.reshape(vgg16_Features[0,:], (-1, feature_size))\n",
        "\n",
        "h_1, curr_state1 = RNNCell(W_RNN1, b_RNN1, RNN_inputs, curr_state1)\n",
        "\n",
        "fc1 = tf.matmul(h_1, W_fc1) + b_fc1\n",
        "print(fc1[0,:].shape, vgg16_Features[1,:].shape)\n",
        "sseLoss1 = tf.square(tf.subtract(fc1[0,:], vgg16_Features[1,:]))\n",
        "mask = tf.greater(sseLoss1, learnError * tf.ones_like(sseLoss1))\n",
        "sseLoss1 = tf.multiply(sseLoss1, tf.cast(mask, tf.float32))\n",
        "sseLoss = tf.reduce_mean(sseLoss1)\n",
        "\n",
        "# Optimization\n",
        "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(sseLoss)\n",
        "\n",
        "\n",
        "#####################\n",
        "### Training loop ###\n",
        "#####################\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"vgg_16\"))\n",
        "with tf.Session() as sess:\n",
        "\t# Initialize parameters\n",
        "\tsess.run(init)\n",
        "\tsaver.restore(sess, \"./vgg_16.ckpt\")\n",
        "\tsaver = tf.train.Saver(max_to_keep=0)\n",
        "\tavgPredError = 1.0\n",
        "\n",
        "\t### In case of interruption, load parameters from the last iteration (ex: 29)\n",
        "\t#saver.restore(sess, './model_stacked_lstm_29')\n",
        "\t### And update the loop to account for the previous iterations\n",
        "\t#for i in range(29,n_epochs):\n",
        "\tstep = 0\n",
        "\tnew_state = np.random.uniform(-0.5,high=0.5,size=(1,n_hidden1))\n",
        "\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# Run 1 epoch\n",
        "\t\tloss = []\n",
        "\t\tshuffle(batch)\n",
        "\n",
        "\t\tfor miniBatchPath in batch:\n",
        "\t\t\tnew_state = np.random.uniform(-0.5,high=0.5,size=(1,n_hidden1))\n",
        "\t\t\tavgPredError = 0\n",
        "\t\t\tvidName, minibatches = loadMiniBatch(miniBatchPath)\n",
        "\t\t\tsegCount = 0\n",
        "\t\t\tpredError = collections.deque(maxlen=30)\n",
        "\t\t\tprint('Video:', vidName)\n",
        "\t\t\tfor x_train in minibatches:\n",
        "\t\t\t\tsegCount += 1\n",
        "\t\t\t\tret = sess.run([train_op, sseLoss, sseLoss1, curr_state1, fc1], feed_dict = {inputs: x_train, is_training: True, init_state1: new_state, learning_rate:lr})\n",
        "\t\t\t\tnew_state = ret[3]\n",
        "\n",
        "\t\t\t\tif activeLearning:\n",
        "\t\t\t\t\tif ret[1]/avgPredError > 1.5:\n",
        "\t\t\t\t\t \tlr = 1e-8\n",
        "\t\t\t\t\t\t#print('Gating n_steps=', segCount, avgPredError, ret[1])\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t#print('NOT Gating n_steps=', segCount, avgPredError, ret[1])\n",
        "\t\t\t\t\t \tlr = 1e-10\n",
        "\t\t\t\tpredError.append(ret[1])\n",
        "\t\t\t\tavgPredError = np.mean(predError)\n",
        "\n",
        "\t\tpath = modelPath + str(i+1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}